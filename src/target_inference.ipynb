{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishengkun/miniconda3/envs/transgen/lib/python3.8/site-packages/torchkge/utils/data_redundancy.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchkge.sampling import BernoulliNegativeSampler\n",
    "from torchkge.utils import MarginLoss,DataLoader\n",
    "from torchkge import KnowledgeGraph,DistMultModel,TransEModel,TransRModel\n",
    "from torchkge.models.bilinear import HolEModel,ComplExModel\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This section is user defined !!!\n",
    "'''\n",
    "h_dim = 300\n",
    "\n",
    "data_path = \"../processed_data/ddr1/\"\n",
    "save_model_path = '../best_model/ddr1/'\n",
    "output_path = \"../results/ddr1/\"\n",
    "\n",
    "ent_list = ['CP1_B+10_B','CP1_SP+10_SP','CP1_B+LPS+10_B+LPS',\n",
    "            'CP1_SP+LPS+10_SP+LPS','CP1_T+10_T','CP1_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed_data after training\n",
    "cause = pd.read_csv(data_path + 'cause.txt',sep='\\t',names=['from','rel','to'])\n",
    "ent2id = np.load(data_path + 'ent2id.npy', allow_pickle=True).item()\n",
    "rel2id = np.load(data_path + 'rel2id.npy', allow_pickle=True).item()\n",
    "\n",
    "h_cand = [v for k,v in ent2id.items() if k.startswith('CID:')]\n",
    "h_cand_ent = [k for k,v in ent2id.items() if k.startswith('CID:')]\n",
    "\n",
    "t_cand = [v for k,v in ent2id.items() if k.startswith(('Protein:','TF:','RBP:'))]\n",
    "t_cand_ent = [k for k,v in ent2id.items() if k.startswith(('Protein:','TF:','RBP:'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count target inference score\n",
    "ti_dict = {}\n",
    "\n",
    "for ent in tqdm.tqdm(ent_list):\n",
    "    results = []\n",
    "    for i in range(5):\n",
    "        model = DistMultModel(h_dim, len(ent2id), len(rel2id))\n",
    "        model.load_state_dict(torch.load(save_model_path + \"pertkg{}.pt\".format(i)))\n",
    "        if cuda.is_available():\n",
    "            cuda.empty_cache()\n",
    "            model.cuda()\n",
    "        model.normalize_parameters()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            ent_emb,rel_emb = model.get_embeddings() # (n_ent, emb_dim)\n",
    "            score = inference(ent,\n",
    "                            ent2id,rel2id,\n",
    "                            ent_emb,rel_emb,\n",
    "                            h_cand,t_cand,\n",
    "                            'target_inference')\n",
    "            results.append(score)\n",
    "\n",
    "    average_list = [sum(x) / len(x) for x in zip(*results)]\n",
    "    ti_dict['{}'.format(ent)] = average_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count confidence\n",
    "results = []\n",
    "for i in range(5):\n",
    "    model = DistMultModel(h_dim, len(ent2id), len(rel2id))\n",
    "    model.load_state_dict(torch.load(save_model_path + \"pertkg{}.pt\".format(i)))\n",
    "    if cuda.is_available():\n",
    "        cuda.empty_cache()\n",
    "        model.cuda()\n",
    "    model.normalize_parameters()\n",
    "    model.eval()\n",
    "    with torch.no_grad():        \n",
    "        ent_emb,rel_emb = model.get_embeddings() # (n_ent, emb_dim)\n",
    "        score = inference(h_cand_ent,\n",
    "                        ent2id,rel2id,\n",
    "                        ent_emb,rel_emb,\n",
    "                        h_cand,t_cand,\n",
    "                        'batch_target_inference')\n",
    "        results.append(score)\n",
    "\n",
    "arr1 = np.array(results[0])\n",
    "arr2 = np.array(results[1])\n",
    "arr3 = np.array(results[2])\n",
    "arr4 = np.array(results[3])\n",
    "arr5 = np.array(results[4])\n",
    "average_arr = np.mean([arr1, arr2, arr3, arr4, \n",
    "                       arr5,\n",
    "                       ], axis=0).tolist()\n",
    "\n",
    "ti_dict_n_n = {}\n",
    "for idx, ent in enumerate(h_cand_ent):\n",
    "    ti_dict_n_n['{}'.format(ent)] = average_arr[idx]\n",
    "\n",
    "ti_percent_dict = {}\n",
    "for k,v in tqdm.tqdm(ti_dict.items()):  \n",
    "    ti_percent = []\n",
    "\n",
    "    k_ranks = get_rank(v)\n",
    "\n",
    "    comp_ranks = []\n",
    "    for comp in h_cand_ent:  \n",
    "        comp_ranks.append(get_rank(ti_dict_n_n[comp]))\n",
    "        \n",
    "    packed_ranks = list(zip(*comp_ranks))\n",
    "\n",
    "    for idx,x in enumerate(k_ranks):\n",
    "        ranks = packed_ranks[idx]\n",
    "        ti_percent.append(sum([1 for i in ranks if i >= (x+50)])/len(ranks))  # 50 is correct factor\n",
    "\n",
    "    ti_percent_dict[k] = ti_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output \n",
    "for k,v in ti_dict.items():\n",
    "    ti_score = v\n",
    "    ti_percent = ti_percent_dict[k]\n",
    "    df = pd.DataFrame({'target':t_cand_ent,\n",
    "                       'ti_score':ti_score,\n",
    "                       'confidence':ti_percent})\n",
    "    df.to_csv(output_path + '{}.txt'.format(k),sep='\\t',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
